{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjDDWmb_78wU",
        "outputId": "b2f784d6-53b1-4786-b7e3-a7be8703cb9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content\n",
            "fatal: destination path 'KGroot' already exists and is not an empty directory.\n",
            "/content/KGroot\n",
            "total 1264\n",
            "drwxr-xr-x 3 root root   4096 Oct  5 15:15 .\n",
            "drwxr-xr-x 1 root root   4096 Oct  5 15:15 ..\n",
            "-rw-r--r-- 1 root root  83328 Oct  5 15:15 cal_faults.py\n",
            "-rw-r--r-- 1 root root    954 Oct  5 15:15 config_graph_sim.ini\n",
            "-rw-r--r-- 1 root root   1165 Oct  5 15:15 config_graph_sim_nogcn.ini\n",
            "-rw-r--r-- 1 root root   1164 Oct  5 15:15 config_graph_sim_nokb.ini\n",
            "-rw-r--r-- 1 root root      1 Oct  5 15:15 data\n",
            "-rw-r--r-- 1 root root 996998 Oct  5 15:15 data.zip\n",
            "drwxr-xr-x 8 root root   4096 Oct  5 15:15 .git\n",
            "-rw-r--r-- 1 root root  27671 Oct  5 15:15 graph_sim_dej_X.py\n",
            "-rw-r--r-- 1 root root  24702 Oct  5 15:15 graph_sim_no_gcn_dej_X.py\n",
            "-rw-r--r-- 1 root root  53098 Oct  5 15:15 graph_sim_no_kb_dej_X.py\n",
            "-rw-r--r-- 1 root root  18610 Oct  5 15:15 model_batch.py\n",
            "-rw-r--r-- 1 root root  10881 Oct  5 15:15 model.py\n",
            "-rw-r--r-- 1 root root  10434 Oct  5 15:15 Radm.py\n",
            "-rw-r--r-- 1 root root    961 Oct  5 15:15 README.md\n",
            "-rw-r--r-- 1 root root   5251 Oct  5 15:15 requirements.txt\n",
            "-rw-r--r-- 1 root root  10214 Oct  5 15:15 tensorboard_logger.py\n",
            "Files of interest:\n",
            "-rw-r--r-- 1 root root 27671 Oct  5 15:15 graph_sim_dej_X.py\n",
            "-rw-r--r-- 1 root root 10881 Oct  5 15:15 model.py\n",
            "-rw-r--r-- 1 root root  5251 Oct  5 15:15 requirements.txt\n"
          ]
        }
      ],
      "source": [
        "# Mount & clone (run this once)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/daixixiwang/KGroot.git KGroot\n",
        "%cd KGroot\n",
        "\n",
        "# Quick list to confirm key files\n",
        "!ls -la/content/KGroot\n",
        "  File \"/content/KGroot/graph_sim_no_kb_dej_X.py\", line 667\n",
        "    train_data = CustomDatasetNoKB(data_set_id=self.data_set_id, dataset_version=self.dataset_version, dataset_dir=self.dataset_dir_override, dataset_dir=self.dataset_dir_override, max_node_num=self.max_node_num, mode=\"train\",\n",
        "                                                                                                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "SyntaxError: keyword argument repeated: dataset_dir\n",
        "!echo \"Files of interest:\"\n",
        "!ls -la graph_sim_dej_X.py model.py requirements.txt || true\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "abc3viuV9C3g",
        "outputId": "8ddf87b5-7b11-448d-ba0a-5937ba6d11bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting absl-py==0.9.0 (from -r requirements.txt (line 1))\n",
            "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/104.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "âœ… torch version: 2.8.0+cu126\n",
            "CUDA available: False\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'PY' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1042119715.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âŒ Torch import failed:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mPY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'PY' is not defined"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Check PyTorch installation\n",
        "!python - <<'PY'\n",
        "try:\n",
        "    import torch\n",
        "    print(\"âœ… torch version:\", torch.__version__)\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "except Exception as e:\n",
        "    print(\"âŒ Torch import failed:\", e)\n",
        "PY\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEk1e98U9kk-",
        "outputId": "462486f2-2e55-4b55-fdc9-9e3e1680988a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/KGroot\n",
            "./graph_sim_no_kb_dej_X.py:139:            (graph_online[\"fetures\"], graph_online[\"adj\"], graph_online[\"node_index_value\"]))\n",
            "./graph_sim_no_kb_dej_X.py:141:            (graph_kb[\"fetures\"], graph_kb[\"adj\"], graph_kb[\"node_index_value\"]))\n",
            "./graph_sim_no_kb_dej_X.py:187:                (graph_online[\"fetures\"], graph_online[\"adj\"], graph_online[\"node_index_value\"]))\n",
            "./graph_sim_no_kb_dej_X.py:204:                    (graph_kb[\"fetures\"], graph_kb[\"adj\"], graph_kb[\"node_index_value\"]))\n",
            "./graph_sim_no_kb_dej_X.py:236:                (graph_online[\"fetures\"], graph_online[\"adj\"], graph_online[\"node_index_value\"]))\n",
            "./graph_sim_no_kb_dej_X.py:245:                    (graph_kb[\"fetures\"], graph_kb[\"adj\"], graph_kb[\"node_index_value\"]))\n",
            "./graph_sim_no_kb_dej_X.py:317:                graph_online_copy[\"fetures\"] = np.delete(graph_online_copy[\"fetures\"], np.array(index_delete), axis=0)\n",
            "./model.py:24:        :param featureless: ä½¿ç”¨æˆ–è€…å¿½ç•¥è¾“å…¥çš„features\n",
            "./model.py:45:        self.output_dim = output_dim  # number of features per node\n",
            "./model.py:47:        self.featureless = featureless  # use/ignore input features\n",
            "./model.py:83:        features_shape = input_shapes[0]\n",
            "./model.py:84:        output_shape = (features_shape[0], self.output_dim)\n",
            "./model.py:89:        features = torch.tensor(inputs[0], dtype=torch.float32, device=device)\n",
            "./model.py:106:                # logging.info(\"A[i]:{} feature:{}\".format(A[i].shape, features.shape))\n",
            "./model.py:107:                supports.append(torch.spmm(A[i], features))\n",
            "./model.py:179:        self.linear_1 = torch.nn.Linear(in_features=gcn_hidden_dim*2, out_features=linear_hidden_dim, bias=True)\n",
            "./model.py:180:        self.linear_2 = torch.nn.Linear(in_features=linear_hidden_dim, out_features=2, bias=True)\n",
            "./graph_sim_no_kb_dej_X.py:499:        logging.info(\"process_graph_init: features:{} adj:{}\".format(graph[0].shape, graph[1].shape))\n",
            "./graph_sim_no_kb_dej_X.py:544:            \"process_graph_done: features:{} adj_r:{} adj_l:{} self:{}\".format(feature_new.shape, adj_r.shape,\n",
            "./model_batch.py:24:        :param featureless: ä½¿ç”¨æˆ–è€…å¿½ç•¥è¾“å…¥çš„features\n",
            "./model_batch.py:45:        self.output_dim = output_dim  # number of features per node\n",
            "./model_batch.py:47:        self.featureless = featureless  # use/ignore input features\n",
            "./model_batch.py:86:        features_shape = input_shapes[0]\n",
            "./model_batch.py:87:        output_shape = (features_shape[0], self.output_dim)\n",
            "./model_batch.py:97:        features, A_list = inputs[0], inputs[1]\n",
            "./model_batch.py:98:        batch_size = features.shape[0]\n",
            "./model_batch.py:99:        node_num = features.shape[1]\n",
            "./model_batch.py:100:        feature_dim = features.shape[2]\n",
            "./model_batch.py:105:            features = features.unsqueeze(dim=1)\n",
            "./model_batch.py:106:            supports = torch.matmul(A_list, features)\n",
            "./model_batch.py:165:        self.linear_1 = torch.nn.Linear(in_features=gcn_hidden_dim, out_features=linear_hidden_dim, bias=True)\n",
            "./model_batch.py:166:        self.linear_2 = torch.nn.Linear(in_features=linear_hidden_dim, out_features=2, bias=True)\n",
            "./model_batch.py:238:        self.linear_1 = torch.nn.Linear(in_features=input_dim, out_features=linear_hidden_dim, bias=True)\n",
            "./model_batch.py:239:        self.linear_2 = torch.nn.Linear(in_features=linear_hidden_dim, out_features=2, bias=True)\n",
            "./model_batch.py:296:        self.linear_1 = torch.nn.Linear(in_features=gcn_hidden_dim, out_features=linear_hidden_dim, bias=True)\n",
            "./model_batch.py:297:        self.linear_2 = torch.nn.Linear(in_features=linear_hidden_dim, out_features=out_dim, bias=True)\n",
            "./model_batch.py:403:    linear = torch.nn.Linear(in_features= 6, out_features=2, bias=True)\n",
            "./model_batch.py:407:    linear2 = torch.nn.Linear(in_features=3, out_features=2, bias=True)\n"
          ]
        }
      ],
      "source": [
        "# ðŸ§© Cell C â€” Search the KGroot repo for expected feature key\n",
        "%cd /content/KGroot\n",
        "\n",
        "# Search for \"fetures\" (typo form)\n",
        "!grep -RIn \"fetures\" .\n",
        "\n",
        "# Search for \"features\" (correct form)\n",
        "!grep -RIn \"features\" .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J_1Pejn9wt2",
        "outputId": "81ce90aa-99f7-4817-be9f-ce9d8dca1425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Dummy pickle created at: /content/KGroot/test_pickle/dummy_graph.pkl\n",
            "Keys: ['fetures', 'adj', 'node_index_value']\n",
            "fetures shape: (5, 8)\n",
            "Number of adjacency matrices: 3\n",
            "Node indices: [0, 1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "# ðŸ§© Cell D â€” Create and test a dummy pickle\n",
        "import os, pickle, numpy as np\n",
        "\n",
        "# Directory to store test pickle\n",
        "test_dir = \"/content/KGroot/test_pickle\"\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Create dummy data\n",
        "num_nodes = 5\n",
        "input_dim = 8\n",
        "graph_dict = {\n",
        "    \"fetures\": np.random.randn(num_nodes, input_dim).astype(\"float32\"),  # keep the misspelled key\n",
        "    \"adj\": [np.eye(num_nodes, dtype=\"float32\") for _ in range(3)],       # 3 adjacency matrices\n",
        "    \"node_index_value\": list(range(num_nodes))\n",
        "}\n",
        "\n",
        "# Save pickle\n",
        "pickle_path = os.path.join(test_dir, \"dummy_graph.pkl\")\n",
        "with open(pickle_path, \"wb\") as f:\n",
        "    pickle.dump(graph_dict, f)\n",
        "print(f\"âœ… Dummy pickle created at: {pickle_path}\")\n",
        "\n",
        "# Load and verify content\n",
        "with open(pickle_path, \"rb\") as f:\n",
        "    loaded = pickle.load(f)\n",
        "print(\"Keys:\", list(loaded.keys()))\n",
        "print(\"fetures shape:\", loaded[\"fetures\"].shape)\n",
        "print(\"Number of adjacency matrices:\", len(loaded[\"adj\"]))\n",
        "print(\"Node indices:\", loaded[\"node_index_value\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLsOHveS-zWi",
        "outputId": "ce860b50-c23b-44ff-9510-c66254e2295c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Bank dataset path: /content/drive/MyDrive/Bank\n",
            "Files: ['query.csv', 'record.csv', 'telemetry']\n",
            "Telemetry folders: ['.DS_Store', '2021_03_07', '2021_03_25', '2021_03_24', '2021_03_10']\n",
            "query.csv exists? True\n",
            "record.csv exists? True\n"
          ]
        }
      ],
      "source": [
        "# ðŸ§© Cell E â€” Set up and verify Bank dataset path\n",
        "\n",
        "from google.colab import drive\n",
        "import os, json\n",
        "\n",
        "# make sure drive is mounted\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Path to your Bank folder on Drive\n",
        "BANK_PATH = \"/content/drive/MyDrive/Bank\"\n",
        "print(\"âœ… Bank dataset path:\", BANK_PATH)\n",
        "print(\"Files:\", os.listdir(BANK_PATH))\n",
        "\n",
        "# quick check subfolder telemetry\n",
        "tele_dir = os.path.join(BANK_PATH, \"telemetry\")\n",
        "if os.path.exists(tele_dir):\n",
        "    print(\"Telemetry folders:\", os.listdir(tele_dir)[:5])  # show a few dates\n",
        "else:\n",
        "    print(\"âš ï¸ telemetry folder not found inside Bank\")\n",
        "\n",
        "# confirm your CSVs\n",
        "for f in [\"query.csv\", \"record.csv\"]:\n",
        "    fp = os.path.join(BANK_PATH, f)\n",
        "    print(f, \"exists?\" , os.path.exists(fp))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHJYX-vn--jY",
        "outputId": "8327f28a-5ca0-42f8-d12b-60c18bdc7aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Bank config created and set as default.\n",
            "Running short 2-epoch test to validate pipelineâ€¦\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/KGroot/graph_sim_dej_X.py\", line 24, in <module>\n",
            "    from DataSetGraphSimGenerator import DataSetGraphSimGenerator, CustomDataset\n",
            "ModuleNotFoundError: No module named 'DataSetGraphSimGenerator'\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cd /content/KGroot\n",
        "\n",
        "# ðŸ§© Cell F â€” Configure KGroot to use your Bank dataset and run a short test\n",
        "\n",
        "# Create a custom config for Bank\n",
        "cat > config_graph_sim_bank.ini <<'CFG'\n",
        "[data]\n",
        "DATASET = 2\n",
        "dataset_version = 1\n",
        "dataset_dir = /content/drive/MyDrive/Bank\n",
        "train_file = train_labeled_data.json\n",
        "valid_file = valid_labeled_data.json\n",
        "test_file  = test_labeled_data.json\n",
        "\n",
        "[model]\n",
        "input_dim = 100\n",
        "max_node_num = 400\n",
        "support = 3\n",
        "gcn_hidden_dim = 64\n",
        "linear_hidden_dim = 32\n",
        "dropout_rate = 0.2\n",
        "\n",
        "[train]\n",
        "nb_epoch = 2\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0\n",
        "CFG\n",
        "\n",
        "# overwrite default config with your Bank config\n",
        "cp config_graph_sim_bank.ini config_graph_sim.ini\n",
        "\n",
        "echo \"âœ… Bank config created and set as default.\"\n",
        "echo \"Running short 2-epoch test to validate pipelineâ€¦\"\n",
        "\n",
        "# Run KGroot\n",
        "python graph_sim_dej_X.py 2>&1 | tee short_bank_run.log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17z_wasC_vgv",
        "outputId": "50a88f54-a090-4963-d159-25c89c015cc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Patched graph_sim_dej_X.py to skip missing DataSetGraphSimGenerator\n",
            "  File \"/content/KGroot/graph_sim_dej_X.py\", line 124\n",
            "    ds = # DataSetGraphSimGenerator(data_set_id=self.data_set_id, dataset_version=self.dataset_version)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "SyntaxError: invalid syntax\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cd /content/KGroot\n",
        "\n",
        "# ðŸ§© Cell G â€” Patch KGroot to skip missing DataSetGraphSimGenerator\n",
        "\n",
        "# Comment out the missing import (this module isn't in repo)\n",
        "sed -i 's/from DataSetGraphSimGenerator import/# from DataSetGraphSimGenerator import/' graph_sim_dej_X.py\n",
        "\n",
        "# Comment out any call to DataSetGraphSimGenerator\n",
        "sed -i 's/DataSetGraphSimGenerator/# DataSetGraphSimGenerator/' graph_sim_dej_X.py\n",
        "\n",
        "echo \"âœ… Patched graph_sim_dej_X.py to skip missing DataSetGraphSimGenerator\"\n",
        "\n",
        "# Re-run the training test\n",
        "python graph_sim_dej_X.py 2>&1 | tee short_bank_run.log\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
